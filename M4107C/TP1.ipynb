{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP1 - Handwritten digit recognition using neural networks and convolutional neural networks\n",
    "\n",
    "**M4108C/M4109C - INFOgr2D**\n",
    "\n",
    "*03/2018*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab, we first design and observe the performance of fully connected neural networks (NNs) as well as convolutional neural networks (CNNs) for digit regconition.  \n",
    "This lab uses the MNIST dataset and Keras implementation with Tensorflow backend.\n",
    "Here are some useful links that may help you during the lab.\n",
    "\n",
    "For NNs\n",
    "- (https://www.learnopencv.com/image-classification-using-feedforward-neural-network-in-keras/)\n",
    "- (https://ankivil.com/mnist-database-and-simple-classification-networks/)\n",
    "\n",
    "For CNNs\n",
    "- (https://sefiks.com/2017/11/05/handwritten-digit-recognition-using-cnn-with-keras/)\n",
    "- (http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Load MNIST dataset and show its training and test sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size :  (60000, 28, 28)\n",
      "test size :  (10000, 28, 28)\n",
      "train label :  (60000,)\n",
      "test label :  (10000,)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "# show the training size, test size, number of class\n",
    "print(\"train size : \",x_train.shape)\n",
    "print(\"test size : \",x_test.shape)\n",
    "print(\"train label : \",y_train.shape)\n",
    "print(\"test label : \",y_test.shape)\n",
    "nclass = len(np.unique(y_train))\n",
    "print(\"number of classes:\",nclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2) Display some image samples using matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRfg/KUaEVVpXBLoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1215efe80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# to complete\n",
    "for i in range(0,9):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(x_train[i], cmap=plt.get_cmap('gray')); plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) (If necessary) Reduce the number of training images (for quick training and small-GPU computer)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size :  (60000, 28, 28)\n",
      "train label :  (60000,)\n"
     ]
    }
   ],
   "source": [
    "#x_train = x_train[0:30000,:]\n",
    "#y_train = y_train[0:30000]\n",
    "print(\"train size : \",x_train.shape)\n",
    "print(\"train label : \",y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fully-connected NNs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Preprocess our data\n",
    "- In order to perform fully-connected NNs, we need to first reshape the image (size of 28x28 pixels) to a 1D array (usingthe reshape function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size :  (60000, 784)\n",
      "test size :  (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28*28)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28*28)\n",
    "print(\"train size : \",x_train.shape)\n",
    "print(\"test size : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the data to float and scale the values between 0 to 1\n",
    "- Convert the labels from integer to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "from keras.utils import np_utils\n",
    "y_train_cat = np_utils.to_categorical(y_train, nclass)\n",
    "y_test_cat = np_utils.to_categorical(y_test, nclass)\n",
    "y_train_cat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Define a 2-layer fully connected NN with 256 neurons for the 1st layer and 512 neurons for the 2nd layer. Use the 'sigmoid' activation function for the 2 network layers and 'softmax' for the final output layer. Show the model summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 337,674\n",
      "Trainable params: 337,674\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# define the model\n",
    "model_nn = Sequential()\n",
    "model_nn.add(Dense(256, input_shape=(784,),activation='sigmoid'))\n",
    "model_nn.add(Dense(512, activation='sigmoid'))\n",
    "model_nn.add(Dense(10,activation='softmax')) #Last layer has nclass nodes\n",
    "model_nn.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Compile and train the model. Report the training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3378 - acc: 0.8997     \n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3337 - acc: 0.9012     \n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3323 - acc: 0.9018     \n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3302 - acc: 0.9019     \n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3282 - acc: 0.9043     \n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3276 - acc: 0.9033     \n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3266 - acc: 0.9035     \n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3238 - acc: 0.9046     \n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3232 - acc: 0.9057     \n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3218 - acc: 0.9051     \n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3205 - acc: 0.9052     \n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 4s - loss: 0.3177 - acc: 0.9061     \n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3180 - acc: 0.9059     \n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3175 - acc: 0.9064     \n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3149 - acc: 0.9071     \n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3131 - acc: 0.9077     \n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3143 - acc: 0.9066     \n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3127 - acc: 0.9083     \n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3103 - acc: 0.9086     \n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s - loss: 0.3094 - acc: 0.9089     \n",
      "training time : 67.56728291511536\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# compile the model\n",
    "model_nn.compile(loss='categorical_crossentropy', optimizer =RMSprop(lr=0.001), metrics=[\"accuracy\"])\n",
    "\n",
    "# train the model\n",
    "start_t_mod= time.time()\n",
    "model_nn.fit(x_train, y_train_cat, batch_size=500, epochs = 20)\n",
    "finish_t_mod = time.time()\n",
    "\n",
    "time = finish_t_mod - start_t_mod\n",
    "print(\"training time :\", time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9984/10000 [============================>.] - ETA: 0sTest score: 0.290284365565\n",
      "Test accuracy: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "# \n",
    "score = model_nn.evaluate(x_test, y_test_cat)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Now, start to design your first CNN (with one CONV layer followed by one MAX-POOLING + 1 FC layer). \n",
    "- CONV layer: 32 filters of size: 5x5, with padding, no stride (stride = 1), activation 'Relu'\n",
    "- MAX-POOLING 2x2\n",
    "- FC layer 128 nodes, activation Relu\n",
    "- Output dense layer with activation 'softmax'\n",
    "(Do not forget your activation function)\n",
    "Report the performance. Show the number of parameters as well as computational time. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 32)        832       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 592,074\n",
      "Trainable params: 592,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import time\n",
    "\n",
    "(x_train,y_train), (x_test,y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0],28,28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0],28,28,1)\n",
    "\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_train_cat = np_utils.to_categorical(y_train, nclass)\n",
    "y_test_cat = np_utils.to_categorical(y_test, nclass)\n",
    "\n",
    "# design the model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32,(5,5),input_shape=(28,28,1), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128,activation='relu'))\n",
    "model_cnn.add(Dense(10,activation='softmax'))\n",
    "model_cnn.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 34s - loss: 0.1945 - acc: 0.9400    \n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 33s - loss: 0.0550 - acc: 0.9832    \n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 34s - loss: 0.0370 - acc: 0.9883    \n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 34s - loss: 0.0265 - acc: 0.9918    \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 34s - loss: 0.0201 - acc: 0.9939    \n",
      "training time : 171.2156970500946\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model_cnn.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=RMSprop(lr=0.001))\n",
    "\n",
    "# train the model\n",
    "start_t= time.time()\n",
    "model_cnn.fit(x_train, y_train_cat, batch_size=128, epochs=5)\n",
    "finish_t = time.time()\n",
    "time_cnn = finish_t - start_t\n",
    "print(\"training time :\", time_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s     \n",
      "Test loss: 0.0337150562087\n",
      "Test accuracy: 0.9892\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "\n",
    "score = model_cnn.evaluate(x_test, y_test_cat)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Now, add one more CONV layer followed by on Max pooling. The number of filters and filter size to be chosen by yourself. \n",
    "Report the performance. Report the performance. Show the number of parameters as well as computational time. \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# design new model\n",
    "# design the model\n",
    "model_cnn = Sequential()\n",
    "model_cnn.add(Conv2D(32,(5,5),input_shape=(28,28,1), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cnn.add(Conv2D(32,(5,5), activation='relu'))\n",
    "model_cnn.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model_cnn.add(Flatten())\n",
    "model_cnn.add(Dense(128,activation='relu'))\n",
    "model_cnn.add(Dense(10,activation='softmax'))\n",
    "model_cnn.summary()\n",
    "\n",
    "\n",
    "# compile the model\n",
    "\n",
    "\n",
    "# train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. CNNs (advanced) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to design other CNNs by:\n",
    "- adding more layers (conv layer, FC layer)? \n",
    "- using Batch normalization? \n",
    "- using Dropout? \n",
    "- sing Data augmentation?\n",
    "\n",
    "Report the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch normalization\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Drop out\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# design new model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
